{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from random import randint, sample\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tqdm import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "tfd, tfb = tfp.distributions, tfp.bijectors\n",
    "tfm, tfla, tfr, tfs = tf.math, tf.linalg, tf.random, tf.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf969dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kron(A, B):\n",
    "    tmp1 = A[None, None, :, :] * B[:, :, None, None]\n",
    "    shape = [tf.shape(A)[0]*tf.shape(B)[0], tf.shape(A)[1]*tf.shape(B)[1]]\n",
    "    return tf.reshape(tf.transpose(tmp1, [0, 2, 1, 3]), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateAlpha(params, dtype=np.float64):\n",
    "    \n",
    "    EtaList = params['Eta']\n",
    "    \n",
    "    sDim = params['sDim']\n",
    "    alphapwList = params['alphapw']\n",
    "        \n",
    "    LiWgList = params['LiWg']\n",
    "    detWgList = params['detWg']\n",
    "    \n",
    "    nr = len(EtaList)\n",
    "    AlphaList = [None] * nr\n",
    "    for r, (Eta, LiWg, detWg, alphapw) in enumerate(zip(EtaList, LiWgList, detWgList, alphapwList)):\n",
    "        np = Eta.shape[0]\n",
    "        nf = tf.cast(tf.shape(Eta)[1], tf.int32)\n",
    "        if sDim[r] > 0:\n",
    "            EtaTiWEta = tf.reduce_sum(tf.matmul(LiWg, Eta)**2, axis=1)\n",
    "            logLike = tfm.log(alphapw[:,1]) - 0.5*detWg - 0.5*tfla.matrix_transpose(EtaTiWEta)    \n",
    "            like = tfm.exp(logLike - tf.math.reduce_logsumexp(logLike, axis=-1, keepdims=True))\n",
    "            AlphaList[r] = tfr.categorical(like, 1, dtype=tf.int64)\n",
    "        else:\n",
    "            AlphaList[r] = tf.zeros([nf,1], tf.int64)\n",
    "            \n",
    "    return AlphaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateEta(params, dtype=np.float64):\n",
    "    \n",
    "    sigma = params['sigma']\n",
    "    \n",
    "    sDim = params['sDim']\n",
    "    Pi = params['Pi']\n",
    "\n",
    "    Z = params['Z']\n",
    "    Beta = params['BetaLambda']['Beta']\n",
    "    EtaList = params['Eta']\n",
    "    LambdaList = params['BetaLambda']['Lambda']\n",
    "    AlphaList = params['Alpha']\n",
    "    X = params['X']\n",
    "    iWgList = params['iWg']\n",
    "                         \n",
    "    npVec = tf.reduce_max(Pi, 0) + 1\n",
    "\n",
    "    nr = len(LambdaList)\n",
    "\n",
    "    LFix = tf.matmul(X, Beta)\n",
    "\n",
    "    LRanLevelList = [None] * nr\n",
    "    for r, (Eta, Lambda) in enumerate(zip(EtaList, LambdaList)):\n",
    "        LRanLevelList[r] = tf.matmul(tf.gather(Eta, Pi[:, r]), Lambda)\n",
    "\n",
    "    iD = tf.ones_like(Z) * sigma**-2\n",
    "\n",
    "    EtaListNew = [None] * nr\n",
    "\n",
    "    for r, (Eta, Lambda, Alpha, iWg) in enumerate(\n",
    "        zip(EtaList, LambdaList, AlphaList, iWgList)\n",
    "    ):\n",
    "\n",
    "        S = (\n",
    "            Z\n",
    "            - LFix\n",
    "            - sum([LRanLevelList[rInd] for rInd in np.setdiff1d(np.arange(nr), r)])\n",
    "        )\n",
    "\n",
    "        nf = tf.cast(tf.shape(Lambda)[-2], tf.int64)\n",
    "\n",
    "        LamInvSigLam = tf.scatter_nd(\n",
    "            Pi[:, r, None],\n",
    "            tf.einsum(\"hj,ij,kj->ihk\", Lambda, iD, Lambda),\n",
    "            tf.stack([npVec[r], nf, nf]),\n",
    "        )\n",
    "\n",
    "        mu0 = tf.scatter_nd(\n",
    "            Pi[:, r, None],\n",
    "            tf.matmul(iD * S, Lambda, transpose_b=True),\n",
    "            tf.stack([npVec[r], nf]),\n",
    "        )\n",
    "\n",
    "        if sDim[r] > 0:\n",
    "            Eta = modelSpatialFull(\n",
    "                Eta, Lambda, LamInvSigLam, mu0, Alpha, iWg, npVec[r], nf\n",
    "            )\n",
    "        else:\n",
    "            Eta = modelNonSpatial(\n",
    "                Eta, Lambda, LamInvSigLam, mu0, npVec[r], nf\n",
    "            )\n",
    "\n",
    "        EtaListNew[r] = Eta\n",
    "\n",
    "        LRanLevelList[r] = tf.matmul(\n",
    "            tf.gather(EtaListNew[r], Pi[:, r]), Lambda\n",
    "        )\n",
    "\n",
    "    return EtaListNew\n",
    "\n",
    "def modelSpatialFull(Eta, Lambda, LamInvSigLam, mu0, Alpha, iWg, np, nf, dtype=np.float64):\n",
    "    iWs = tf.reshape(\n",
    "        tf.transpose(\n",
    "            tfla.diag(\n",
    "                tf.transpose(tf.gather(iWg, tf.squeeze(Alpha, -1)), [1, 2, 0])\n",
    "            ),\n",
    "            [2, 0, 3, 1],\n",
    "        ),\n",
    "        [nf * np, nf * np],\n",
    "    )\n",
    "    iUEta = iWs + tf.reshape(\n",
    "        tf.transpose(\n",
    "            tfla.diag(tf.transpose(LamInvSigLam, [1, 2, 0])), [0, 2, 1, 3]\n",
    "        ),\n",
    "        [nf * np, nf * np],\n",
    "    )\n",
    "    LiUEta = tfla.cholesky(iUEta)\n",
    "    mu1 = tfla.triangular_solve(\n",
    "        LiUEta, tf.reshape(tf.transpose(mu0), [nf * np, 1])\n",
    "    )\n",
    "    eta = tfla.triangular_solve(\n",
    "        LiUEta, mu1 + tfr.normal([nf * np, 1], dtype=dtype), adjoint=True\n",
    "    )\n",
    "    Eta = tf.transpose(tf.reshape(eta, [nf, np]))\n",
    "    return Eta\n",
    "\n",
    "def modelNonSpatial(Eta, Lambda, LamInvSigLam, mu0, np, nf, dtype=np.float64):\n",
    "    iV = tf.eye(nf, dtype=dtype) + LamInvSigLam\n",
    "    LiV = tfla.cholesky(iV + tf.eye(nf, dtype=dtype))\n",
    "    mu1 = tfla.triangular_solve(LiV, tf.expand_dims(mu0, -1))\n",
    "    Eta = tf.squeeze(\n",
    "        tfla.triangular_solve(\n",
    "            LiV, mu1 + tfr.normal([np, nf, 1], dtype=dtype), adjoint=True\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    return Eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be569ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateGammaV(params, dtype=np.float64):\n",
    "    \n",
    "    Beta = params['BetaLambda']['Beta']\n",
    "    Gamma = params['GammaV']['Gamma']\n",
    "    iV = params['GammaV']['iV']\n",
    "    \n",
    "    T = params['T']\n",
    "    mGamma = params['mGamma']\n",
    "    iUGamma = params['iUGamma']\n",
    "    V0 = params['V0']\n",
    "    f0 = params['f0']\n",
    "    \n",
    "    #nc, ns = Beta.shape\n",
    "    nc = tf.shape(Beta)[0]\n",
    "    ns = tf.shape(Beta)[1]\n",
    "    #print([nc, ns])\n",
    "    nt = Gamma.shape[-1]\n",
    "    Mu = tf.matmul(Gamma, T, transpose_b=True)\n",
    "    E = Beta - Mu\n",
    "    A = tf.matmul(E, E, transpose_b=True)\n",
    "    Vn = tfla.cholesky_solve(tfla.cholesky(A+V0), tf.eye(nc, dtype=dtype))\n",
    "    LVn = tfla.cholesky(Vn)\n",
    "    iV = tfp.distributions.WishartTriL(tf.cast(f0+ns, dtype), LVn).sample()\n",
    "\n",
    "    iSigmaGamma = iUGamma + kron(tf.matmul(T, T, transpose_a=True), iV)\n",
    "    L = tfla.cholesky(iSigmaGamma)\n",
    "    mg0 = tf.matmul(iUGamma, mGamma[:, None]) + tf.reshape(tf.matmul(iV, tf.matmul(Beta, T)), [nc*nt, 1])\n",
    "    mg1 = tfla.triangular_solve(L, mg0)\n",
    "    Gamma = tf.reshape(tfla.triangular_solve(L, mg1 + 0*tfr.normal([nc*nt, 1], dtype=dtype), adjoint=True), [nc, nt])\n",
    "    return {'Gamma': Gamma, 'iV': iV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283537c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateZ(params, dtype=np.float64):\n",
    "    \n",
    "    Beta = params['BetaLambda']['Beta']\n",
    "    EtaList = params['Eta']\n",
    "    LambdaList = params['BetaLambda']['Lambda']\n",
    "    sigma = params['sigma']\n",
    "    \n",
    "    Y = params['Y']\n",
    "    X = params['X']\n",
    "    Pi = params['Pi']\n",
    "    distr = params['distr']\n",
    "        \n",
    "    ny, ns = Y.shape\n",
    "    nr = len(EtaList)\n",
    "    LFix = tf.matmul(X, Beta)\n",
    "    LRanLevelList = [None] * nr\n",
    "    for r, (Eta, Lambda) in enumerate(zip(EtaList, LambdaList)):\n",
    "        LRanLevelList[r] = tf.matmul(tf.gather(Eta, Pi[:,r]), Lambda)\n",
    "    L = LFix + sum(LRanLevelList)\n",
    "    Yo = tfm.logical_not(tfm.is_nan(Y))\n",
    "    \n",
    "    # no data augmentation for normal model in columns with continious unbounded data\n",
    "    indColNormal = tf.squeeze(tf.where(distr[:,0] == 1), -1)\n",
    "    YN  = tf.gather(Y,  indColNormal, axis=-1)\n",
    "    YoN = tf.gather(Yo, indColNormal, axis=-1)\n",
    "    LN = tf.gather(L, indColNormal, axis=-1)\n",
    "    sigmaN = tf.gather(sigma, indColNormal)\n",
    "    ZN = tf.cast(YoN, dtype)*YN + \\\n",
    "        (1-tf.cast(YoN, dtype))*(LN + tfr.normal([ny, tf.size(indColNormal)], dtype=dtype)*sigmaN)\n",
    "\n",
    "    # Albert and Chib (1993) data augemntation for probit model in columns with binary data \n",
    "    indColProbit = tf.squeeze(tf.where(distr[:,0] == 2), -1)\n",
    "    YP  = tf.gather(Y,  indColProbit, axis=-1)\n",
    "    YoP = tf.gather(Yo, indColProbit, axis=-1)\n",
    "    LP = tf.gather(L, indColProbit, axis=-1)\n",
    "    sigmaP = tf.gather(sigma, indColProbit)\n",
    "    low  = tf.where(tfm.logical_or(YP == 0, tfm.logical_not(YoP)), tf.cast(-np.inf, dtype), tf.zeros_like(YP))\n",
    "    high = tf.where(tfm.logical_or(YP == 1, tfm.logical_not(YoP)), tf.cast( np.inf, dtype), tf.zeros_like(YP))\n",
    "    ZP = tfd.TruncatedNormal(loc=LP, scale=sigmaP, low=low, high=high, name='TruncatedNormal').sample()\n",
    "\n",
    "    ZStack = tf.concat([ZN,ZP], -1)\n",
    "    indColStack = tf.concat([indColNormal,indColProbit], 0)\n",
    "    ZNew = tf.transpose(tf.scatter_nd(indColStack[:,None], tf.transpose(ZStack), Y.shape[::-1]))\n",
    "    return ZNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5282846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateBetaLambda(params, dtype=np.float64):\n",
    "    \n",
    "    Z = params['Z']\n",
    "    Gamma = params['GammaV']['Gamma']\n",
    "    iV = params['GammaV']['iV']\n",
    "    EtaList = params['Eta']\n",
    "    PsiList = params['PsiDelta']['Psi']\n",
    "    DeltaList = params['PsiDelta']['Delta']\n",
    "    sigma = params['sigma']\n",
    "    X = params['X']\n",
    "    T = params['T']\n",
    "    Pi = params['Pi']\n",
    "        \n",
    "    ny, nc = X.shape\n",
    "    _, ns = Z.shape\n",
    "    nr = len(EtaList)\n",
    "    nfVec = tf.stack([tf.shape(Eta)[-1] for Eta in EtaList])\n",
    "    nfSum = tf.reduce_sum(nfVec)\n",
    "\n",
    "    EtaListFull = [None] * nr\n",
    "    for r, Eta in enumerate(EtaList):\n",
    "        EtaListFull[r] = tf.gather(Eta, Pi[:,r])\n",
    "\n",
    "    XE = tf.concat([X] + EtaListFull, axis=-1)\n",
    "    GammaT = tf.matmul(Gamma, T, transpose_b=True)\n",
    "    Mu = tf.concat([GammaT, tf.zeros([nfSum, ns], dtype)], axis=0)\n",
    "    LambdaPriorPrec = tf.concat([Psi * tfm.cumprod(Delta, -2) for Psi, Delta in zip(PsiList, DeltaList)], axis=-2)\n",
    "\n",
    "    iK11_op = tfla.LinearOperatorFullMatrix(iV)\n",
    "    iK22_op = tfla.LinearOperatorDiag(tf.transpose(LambdaPriorPrec))\n",
    "    iK = tfla.LinearOperatorBlockDiag([iK11_op, iK22_op]).to_dense()\n",
    "    iU = iK + tf.matmul(XE, XE, transpose_a=True)/(sigma**2)[:, None, None]\n",
    "    LiU = tfla.cholesky(iU)\n",
    "    A = tf.matmul(iK, tf.transpose(Mu)[:,:,None]) + (tf.matmul(Z, XE, transpose_a=True)/(sigma**2)[:, None])[:,:,None]\n",
    "    M = tfla.cholesky_solve(LiU, A)\n",
    "    BetaLambda = tf.transpose(tf.squeeze(M + tfla.triangular_solve(LiU, tf.random.normal(shape=[ns, nc+nfSum, 1], dtype=dtype), adjoint=True), -1))\n",
    "    BetaLambdaList = tf.split(BetaLambda, tf.concat([tf.constant([nc], tf.int32), nfVec], -1), axis=-2)\n",
    "    BetaNew, LambdaListNew = BetaLambdaList[0], BetaLambdaList[1:]\n",
    "    return {'Beta': BetaNew, 'Lambda': LambdaListNew}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateSigma(params, dtype=np.float64):\n",
    "    \n",
    "    Z = params['Z']\n",
    "    Beta = params['BetaLambda']['Beta']\n",
    "    EtaList = params['Eta']\n",
    "    LambdaList = params['BetaLambda']['Lambda']\n",
    "    sigma = params['sigma']\n",
    "    \n",
    "    Y = params['Y']\n",
    "    X = params['X']\n",
    "    Pi = params['Pi']\n",
    "    distr = params['distr']\n",
    "    aSigma = params['aSigma']\n",
    "    bSigma = params['bSigma']\n",
    "    \n",
    "    nr = len(EtaList)\n",
    "    indVarSigma = tf.cast(tf.equal(distr[:,1], 1), dtype)\n",
    "    LFix = tf.matmul(X, Beta)\n",
    "    LRanLevelList = [None] * nr\n",
    "    for r, (Eta, Lambda) in enumerate(zip(EtaList, LambdaList)):\n",
    "        LRanLevelList[r] = tf.matmul(tf.gather(Eta, Pi[:,r]), Lambda)\n",
    "\n",
    "    L = LFix + sum(LRanLevelList)\n",
    "    Eps = Z - L\n",
    "    \n",
    "    alpha = aSigma + Y.shape[0]/2.\n",
    "    beta = bSigma + tf.reduce_sum(Eps**2, axis=0)/2.\n",
    "    isigma2 = tfp.distributions.Gamma(concentration=alpha, rate=beta).sample()\n",
    "    sigmaNew = indVarSigma*tfm.rsqrt(isigma2) + (1-indVarSigma)*sigma\n",
    "    return sigmaNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateLambdaPriors(params, dtype=np.float64):\n",
    "    \n",
    "    LambdaList = params['BetaLambda']['Lambda']\n",
    "    DeltaList =  params['PsiDelta']['Delta']\n",
    "    \n",
    "    nu = params['nu']\n",
    "    a1 = params['a1']\n",
    "    b1 = params['b1']\n",
    "    a2 = params['a2']\n",
    "    b2 = params['b2']\n",
    "    \n",
    "    nr = len(LambdaList)\n",
    "    PsiNew, DeltaNew = [None] * nr, [None] * nr\n",
    "    for r, (Lambda, Delta) in enumerate(zip(LambdaList, DeltaList)):\n",
    "        ns = Lambda.shape[-1]\n",
    "        nf = tf.shape(Lambda)[0]\n",
    "        if nf > 0:\n",
    "            aDelta = tf.concat([a1[r]*tf.ones([1,1], dtype), a2[r]*tf.ones([nf-1,1], dtype)], 0)\n",
    "            bDelta = tf.concat([b1[r]*tf.ones([1,1], dtype), b2[r]*tf.ones([nf-1,1], dtype)], 0)\n",
    "            Lambda2 = Lambda**2\n",
    "            Tau = tfm.cumprod(Delta, 0)\n",
    "            aPsi = nu[r]/2. + 0.5\n",
    "            bPsi = nu[r]/2. + Lambda2 * Tau\n",
    "            PsiNew[r] = tf.squeeze(tfr.gamma([1], aPsi, bPsi, dtype=dtype), 0)\n",
    "            M = PsiNew[r] * Lambda2\n",
    "            rowSumM = tf.reduce_sum(M, 1)\n",
    "            DeltaNew[r] = Delta\n",
    "            for h in range(nf):\n",
    "                Tau = tfm.cumprod(DeltaNew[r], 0)\n",
    "                ad = aDelta[h,:] + 0.5*ns*tf.cast(nf-h,dtype)\n",
    "                bd = bDelta[h,:] + 0.5*tf.reduce_sum(Tau[h:,:]*rowSumM[h:,None], 0) / DeltaNew[r][h,:]\n",
    "                DeltaNew[r] = tf.tensor_scatter_nd_update(DeltaNew[r], [[h]], tfr.gamma([1], ad, bd, dtype=dtype))\n",
    "        else:\n",
    "            PsiNew[r] = tf.zeros([0,ns], dtype)\n",
    "            DeltaNew[r] = tf.zeros([0,1], dtype)\n",
    "    return {'Psi': PsiNew, 'Delta': DeltaNew}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9636a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateNf(params, dtype=np.float64):\n",
    "    \n",
    "    EtaList = params['Eta']\n",
    "    LambdaList = params['BetaLambda']['Lambda']\n",
    "    PsiList = params['PsiDelta']['Psi']\n",
    "    DeltaList =  params['PsiDelta']['Delta']\n",
    "\n",
    "    # iter ???\n",
    "    iter = 1\n",
    "    \n",
    "    nu = params['nu']\n",
    "    a2 = params['a2']\n",
    "    b2 = params['b2']\n",
    "    nfMin = params['nfMin']\n",
    "    nfMax = params['nfMax']\n",
    "        \n",
    "    c0 = 1\n",
    "    c1 = 0.0005\n",
    "    epsilon = 1e-3 # threshold limit\n",
    "    prop = 1.00 # proportion of redundant elements within columns\n",
    "    prob = 1/tf.exp(c0 + c1*tf.cast(iter, dtype)) # probability of adapting\n",
    "    \n",
    "    nr = len(LambdaList)\n",
    "    EtaNew, LambdaNew, PsiNew, DeltaNew = [[None] * nr for i in range(4)] \n",
    "    for r, (Eta, Lambda, Psi, Delta) in enumerate(zip(EtaList, LambdaList, PsiList, DeltaList)):\n",
    "        if tfr.uniform([], dtype=dtype) < prob:\n",
    "            nf = tf.shape(Lambda)[0]\n",
    "            _, ns = Lambda.shape\n",
    "            np = tf.shape(Eta)[0]\n",
    "            smallLoadingProp = tf.reduce_mean(tf.cast(tfm.abs(Lambda) < epsilon, dtype=dtype), axis=1)\n",
    "            indRedundant = smallLoadingProp >= prop\n",
    "            numRedundant = tf.reduce_sum(tf.cast(indRedundant, dtype=dtype))\n",
    "          \n",
    "            if nf < nfMax[r] and iter > 20 and numRedundant == 0: #and tf.reduce_all(smallLoadingProp < 0.995):\n",
    "              EtaNew[r] = tf.concat([Eta, tfr.normal([np,1], dtype=dtype)], axis=1)\n",
    "              LambdaNew[r] = tf.concat([Lambda, tf.zeros([1,ns], dtype=dtype)], axis=0)\n",
    "              PsiNew[r] = tf.concat([Psi, tfr.gamma([1,ns], nu[r]/2, nu[r]/2, dtype=dtype)], axis=0)\n",
    "              DeltaNew[r] = tf.concat([Delta, tfr.gamma([1,1], a2[r], b2[r], dtype=dtype)], axis=0)\n",
    "            elif nf > nfMin[r] and numRedundant > 0:\n",
    "              indRemain = tf.cast(tf.squeeze(tf.where(tfm.logical_not(indRedundant)), -1), tf.int32)\n",
    "              if tf.shape(indRemain)[0] < nfMin[r]:\n",
    "                indRemain = tf.concat([indRemain, nf-1-tf.range(nfMin[r]-tf.shape(indRemain)[0])], axis=0)\n",
    "              EtaNew[r] = tf.gather(Eta, indRemain, axis=1)\n",
    "              LambdaNew[r] = tf.gather(Lambda, indRemain, axis=0)\n",
    "              PsiNew[r] = tf.gather(Psi, indRemain, axis=0)\n",
    "              DeltaNew[r] = tf.gather(Delta, indRemain, axis=0)\n",
    "            else:\n",
    "              EtaNew[r], LambdaNew[r], PsiNew[r], DeltaNew[r] = Eta, Lambda, Psi, Delta\n",
    "        else:\n",
    "          EtaNew[r], LambdaNew[r], PsiNew[r], DeltaNew[r] = Eta, Lambda, Psi, Delta\n",
    "    return {'Eta': EtaNew, 'Lambda': LambdaNew, 'Psi': PsiNew, 'Delta': DeltaNew}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GibbsParameter():\n",
    "    \n",
    "    def __init__(self, value, conditional_posterior, posterior_params = None):\n",
    "        self.value = value\n",
    "        self.conditional_posterior = conditional_posterior\n",
    "        self.posterior_params = posterior_params\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        pass\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.value)\n",
    "    \n",
    "    def sample(self, sample_params):\n",
    "        param_values = {}\n",
    "        for k, v in sample_params.items():\n",
    "            if isinstance(v, GibbsParameter):\n",
    "                param_values[k] = v.value\n",
    "            else:\n",
    "                param_values[k] = v\n",
    "        post_params = param_values\n",
    "        self.value = self.conditional_posterior(post_params)\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b38268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GibbsSampler:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def single_sample(self, param_name):    \n",
    "        value = self.params[param_name].sample(self.params)\n",
    "        self.params[param_name].value = value\n",
    "        return value\n",
    "    \n",
    "    @tf.function\n",
    "    def sampling_routine(self, num_samples, sample_period = 1, sample_burnin = 0, sample_thining = 1, printRetraceFlag = True):\n",
    "        if printRetraceFlag:\n",
    "            print(\"retracing\")\n",
    "        \n",
    "        params = self.params\n",
    "        history = []\n",
    "        step_num = sample_burnin + num_samples*sample_thining\n",
    "        for n in range(step_num):\n",
    "            row = {}\n",
    "            for key in list(params.keys()):\n",
    "                if isinstance(params[key], GibbsParameter):\n",
    "                    row[key] = self.single_sample(key)\n",
    "            if ((n >= sample_burnin) & (n % sample_period == 0)):\n",
    "                history.append(row)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983542ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c42675a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from random import randint, sample\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tqdm import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "tfd, tfb = tfp.distributions, tfp.bijectors\n",
    "tfm, tfla, tfr, tfs = tf.math, tf.linalg, tf.random, tf.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd59be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmsc.gibbs_sampler import GibbsParameter, GibbsSampler\n",
    "\n",
    "from hmsc.updaters.updateEta import updateEta\n",
    "from hmsc.updaters.updateAlpha import updateAlpha\n",
    "from hmsc.updaters.updateBetaLambda import updateBetaLambda\n",
    "from hmsc.updaters.updateLambdaPriors import updateLambdaPriors\n",
    "from hmsc.updaters.updateNf import updateNf\n",
    "from hmsc.updaters.updateGammaV import updateGammaV\n",
    "from hmsc.updaters.updateSigma import updateSigma\n",
    "from hmsc.updaters.updateZ import updateZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85ffd1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retracing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/gibbs_sampler.py\", line 55, in sampling_routine  *\n        row[key] = self.single_sample(key)\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/gibbs_sampler.py\", line 32, in single_sample  *\n        value = self.params[param_name].sample(self.params)\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/gibbs_sampler.py\", line 23, in sample  *\n        self.value = self.conditional_posterior(post_params)\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/updaters/updateZ.py\", line 19, in updateZ  *\n        nr = len(EtaList)\n\n    NameError: name 'EtaList' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m postList \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m nChains\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chain \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nChains):\n\u001b[0;32m---> 11\u001b[0m     postList[chain] \u001b[38;5;241m=\u001b[39m \u001b[43mgibbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_routine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m elapsedTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m startTime\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTF decorated whole cycle elapsed \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m elapsedTime)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/j8/4jbvn5g510v_0m8jtlnbjdk40000gp/T/__autograph_generated_filexlagb5iq.py:75\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__sampling_routine\u001b[0;34m(self, num_samples, sample_period, sample_burnin, sample_thining, printRetraceFlag)\u001b[0m\n\u001b[1;32m     73\u001b[0m key \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     74\u001b[0m n \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mrange\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(step_num),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body_1, get_state_4, set_state_4, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/j8/4jbvn5g510v_0m8jtlnbjdk40000gp/T/__autograph_generated_filexlagb5iq.py:58\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__sampling_routine.<locals>.loop_body_1\u001b[0;34m(itr_1)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28misinstance\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(params)[ag__\u001b[38;5;241m.\u001b[39mld(key)], ag__\u001b[38;5;241m.\u001b[39mld(GibbsParameter)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow[key]\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_3\u001b[39m():\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/var/folders/j8/4jbvn5g510v_0m8jtlnbjdk40000gp/T/__autograph_generated_filexlagb5iq.py:57\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__sampling_routine.<locals>.loop_body_1.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_1\u001b[39m():\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGibbsParameter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrow[key]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/j8/4jbvn5g510v_0m8jtlnbjdk40000gp/T/__autograph_generated_filexlagb5iq.py:53\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__sampling_routine.<locals>.loop_body_1.<locals>.loop_body.<locals>.if_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body_1\u001b[39m():\n\u001b[0;32m---> 53\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mld(row)[ag__\u001b[38;5;241m.\u001b[39mld(key)] \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/j8/4jbvn5g510v_0m8jtlnbjdk40000gp/T/__autograph_generated_filezwusrc2d.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__single_sample\u001b[0;34m(self, param_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m value \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mparams[ag__\u001b[38;5;241m.\u001b[39mld(param_name)]\u001b[38;5;241m.\u001b[39msample, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mparams,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mparams[ag__\u001b[38;5;241m.\u001b[39mld(param_name)]\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(value)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/j8/4jbvn5g510v_0m8jtlnbjdk40000gp/T/__autograph_generated_file1zdobo5d.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__sample\u001b[0;34m(self, sample_params)\u001b[0m\n\u001b[1;32m     35\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(sample_params)\u001b[38;5;241m.\u001b[39mitems, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state_1, set_state_1, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(k, v)\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     36\u001b[0m post_params \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(param_values)\n\u001b[0;32m---> 37\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconditional_posterior, (ag__\u001b[38;5;241m.\u001b[39mld(post_params),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/j8/4jbvn5g510v_0m8jtlnbjdk40000gp/T/__autograph_generated_filejruehfkj.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__updateZ\u001b[0;34m(params, dtype)\u001b[0m\n\u001b[1;32m     13\u001b[0m distr \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(params)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m (ny, ns) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(Y)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 15\u001b[0m nr \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlen\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(EtaList),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m LFix \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmatmul, (ag__\u001b[38;5;241m.\u001b[39mld(X), ag__\u001b[38;5;241m.\u001b[39mld(Beta)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     17\u001b[0m LRanLevelList \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(nr)\n",
      "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/gibbs_sampler.py\", line 55, in sampling_routine  *\n        row[key] = self.single_sample(key)\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/gibbs_sampler.py\", line 32, in single_sample  *\n        value = self.params[param_name].sample(self.params)\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/gibbs_sampler.py\", line 23, in sample  *\n        self.value = self.conditional_posterior(post_params)\n    File \"/Users/anisjyu/Dropbox/hmsc-hpc/hmsc-hpc/hmsc/updaters/updateZ.py\", line 19, in updateZ  *\n        nr = len(EtaList)\n\n    NameError: name 'EtaList' is not defined\n"
     ]
    }
   ],
   "source": [
    "sampler_params = {\n",
    "    'Z': GibbsParameter(Z, updateZ),\n",
    "}\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "gibbs = GibbsSampler(params = {**sampler_params, **prior_params, **random_level_params, **random_level_data_params, **model_data})\n",
    "\n",
    "postList = [None] * nChains\n",
    "for chain in range(nChains):\n",
    "    postList[chain] = gibbs.sampling_routine(3)\n",
    "\n",
    "elapsedTime = time.time() - startTime\n",
    "print(\"\\nTF decorated whole cycle elapsed %.1f\" % elapsedTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_params = {\n",
    "    'Z': GibbsParameter(Z, updateZ),\n",
    "    'BetaLambda': GibbsParameter({'Beta': Beta, 'Lambda': LambdaList}, updateBetaLambda),\n",
    "    'GammaV': GibbsParameter({'Gamma': Gamma, 'iV': iV}, updateGammaV),\n",
    "    'PsiDelta': GibbsParameter({'Psi': PsiList, 'Delta': DeltaList}, updateLambdaPriors),\n",
    "    'Eta': GibbsParameter(EtaList, updateEta),    \n",
    "    'sigma': GibbsParameter(sigma, updateSigma),\n",
    "    'Nf': GibbsParameter({'Eta': EtaList, 'Lambda': LambdaList, 'Psi': PsiList, 'Delta': DeltaList}, updateNf),\n",
    "    'Alpha': GibbsParameter(AlphaList, updateAlpha),\n",
    "}\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "gibbs = GibbsSampler(params = {**sampler_params, **prior_params, **random_level_params, **random_level_data_params, **model_data})\n",
    "\n",
    "postList = [None] * nChains\n",
    "for chain in range(nChains):\n",
    "    postList[chain] = gibbs.sampling_routine(3)\n",
    "\n",
    "elapsedTime = time.time() - startTime\n",
    "print(\"\\nTF decorated whole cycle elapsed %.1f\" % elapsedTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826f9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6ea1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294dd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(postList[chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dcee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "postList[chain][0]['Alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2447dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_test(params):\n",
    "    t1 = params['sDim']\n",
    "    t2 = params['sDim'] + 1\n",
    "    return {'t1': t1, 't2': t2}\n",
    "\n",
    "update_test(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c62209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_test(params):\n",
    "    t1 = params['test']['t1'] + 1\n",
    "    t2 = params['test']['t2']\n",
    "    return {'t1': t1, 't2': t2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d71784",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_params = {\n",
    "    'test': GibbsParameter({'t1': sDim, 't2': alphapw}, update_test),\n",
    "}\n",
    "\n",
    "gibbs = GibbsSampler(params = {**sampler_params, **prior_params, **random_level_params, **random_level_data_params, **model_data})\n",
    "res = gibbs.sampling_routine(2)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69329d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5577713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFunction(i, samInd, LambdaShapeList):\n",
    "    outStr = \"iteration \" + str(i.numpy())\n",
    "    if samInd.numpy() >= 0:\n",
    "        outStr += \" saving \" + str(samInd.numpy())\n",
    "    else:\n",
    "        outStr += \" transient\"\n",
    "    outStr += \" Lambda shape \" + str(\n",
    "        [str(LambdaShape.numpy()) for LambdaShape in LambdaShapeList]\n",
    "    )\n",
    "    sys.stdout.write(\"\\r\" + outStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9007d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GibbsSampler:\n",
    "    def __init__(self, nChains, samN, thinN):\n",
    "        self.params = {}\n",
    "\n",
    "        self.params[\"nChains\"] = nChains\n",
    "        self.params[\"samN\"] = samN\n",
    "        self.params[\"thinN\"] = thinN\n",
    "\n",
    "        self.params[\"transient\"] = samN * thinN\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(\n",
    "        self,\n",
    "        Z,\n",
    "        Beta,\n",
    "        Gamma,\n",
    "        iV,\n",
    "        EtaList,\n",
    "        LambdaList,\n",
    "        PsiList,\n",
    "        DeltaList,\n",
    "        AlphaList,\n",
    "        sigma,\n",
    "        modelData,\n",
    "        priorHyperParList,\n",
    "        rLParList,\n",
    "        rLDataParList,\n",
    "    ):\n",
    "        startTime = time.time()\n",
    "\n",
    "        postList = [None] * self.params[\"nChains\"]\n",
    "        for chain in range(self.params[\"nChains\"]):\n",
    "            postList[chain] = self.do_sampling(\n",
    "                Z,\n",
    "                Beta,\n",
    "                Gamma,\n",
    "                iV,\n",
    "                EtaList,\n",
    "                LambdaList,\n",
    "                PsiList,\n",
    "                DeltaList,\n",
    "                AlphaList,\n",
    "                sigma,\n",
    "                modelData,\n",
    "                priorHyperParList,\n",
    "                rLParList,\n",
    "                rLDataParList,\n",
    "            )\n",
    "\n",
    "        elapsedTime = time.time() - startTime\n",
    "        print(\"\\nTF decorated whole cycle elapsed %.1f\" % elapsedTime)\n",
    "\n",
    "        return postList\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        Z,\n",
    "        Beta,\n",
    "        Gamma,\n",
    "        iV,\n",
    "        EtaList,\n",
    "        LambdaList,\n",
    "        PsiList,\n",
    "        DeltaList,\n",
    "        AlphaList,\n",
    "        sigma,\n",
    "        itInd,\n",
    "        modelData,\n",
    "        priorHyperParList,\n",
    "        rLParList,\n",
    "        rLDataParList,\n",
    "        printRetraceFlag=True,\n",
    "    ):\n",
    "        if printRetraceFlag:\n",
    "            print(\"retracing\")\n",
    "\n",
    "        sampler = UpdateEta(sigma, rLParList['sDim'], modelData['Pi'])\n",
    "        EtaListNew = sampler(\n",
    "            Z, Beta, EtaList, LambdaList, AlphaList, modelData['X'], rLDataParList['iWg']\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            Z,\n",
    "            Beta,\n",
    "            Gamma,\n",
    "            iV,\n",
    "            EtaListNew,\n",
    "            LambdaList,\n",
    "            PsiList,\n",
    "            DeltaList,\n",
    "            AlphaList,\n",
    "            sigma,\n",
    "        )\n",
    "\n",
    "    def do_sampling(\n",
    "        self,\n",
    "        Z,\n",
    "        Beta,\n",
    "        Gamma,\n",
    "        iV,\n",
    "        EtaList,\n",
    "        LambdaList,\n",
    "        PsiList,\n",
    "        DeltaList,\n",
    "        AlphaList,\n",
    "        sigma,\n",
    "        modelData,\n",
    "        priorHyperParList,\n",
    "        rLParList,\n",
    "        rLDataParList,\n",
    "    ):\n",
    "\n",
    "        _, ns = modelData[\"Y\"].shape\n",
    "        nr = len(LambdaList)\n",
    "\n",
    "        samplesGamma, samplesiV, samplesBeta, samplesSigma = [\n",
    "            tf.TensorArray(dtype, size=self.params[\"samN\"]) for i in range(4)\n",
    "        ]\n",
    "        samplesLambdaList = [\n",
    "            tf.TensorArray(dtype, size=self.params[\"samN\"]) for i in range(nr)\n",
    "        ]\n",
    "        samplesEtaList = [\n",
    "            tf.TensorArray(dtype, size=self.params[\"samN\"]) for i in range(nr)\n",
    "        ]\n",
    "        samplesPsiList = [\n",
    "            tf.TensorArray(dtype, size=self.params[\"samN\"]) for i in range(nr)\n",
    "        ]\n",
    "        samplesDeltaList = [\n",
    "            tf.TensorArray(dtype, size=self.params[\"samN\"]) for i in range(nr)\n",
    "        ]\n",
    "\n",
    "        for i in tf.range(\n",
    "            self.params[\"transient\"] + self.params[\"samN\"] * self.params[\"thinN\"]\n",
    "        ):\n",
    "            tf.autograph.experimental.set_loop_options(\n",
    "                shape_invariants=[\n",
    "                    (EtaList, [tf.TensorShape([None, None])] * nr),\n",
    "                    (Beta, tf.TensorShape([None, ns])),\n",
    "                    (LambdaList, [tf.TensorShape([None, ns])] * nr),\n",
    "                    (PsiList, [tf.TensorShape([None, ns])] * nr),\n",
    "                    (DeltaList, [tf.TensorShape([None, 1])] * nr),\n",
    "                    (AlphaList, [tf.TensorShape([None, 1])] * nr),\n",
    "                ]\n",
    "            )\n",
    "            if i < self.params[\"transient\"]:\n",
    "                itInd = tf.cast(i, dtype)\n",
    "            else:\n",
    "                itInd = tf.constant(np.inf, dtype)\n",
    "\n",
    "            (\n",
    "                Z,\n",
    "                Beta,\n",
    "                Gamma,\n",
    "                iV,\n",
    "                EtaList,\n",
    "                LambdaList,\n",
    "                PsiList,\n",
    "                DeltaList,\n",
    "                AlphaList,\n",
    "                sigma,\n",
    "            ) = self.sample(\n",
    "                Z,\n",
    "                Beta,\n",
    "                Gamma,\n",
    "                iV,\n",
    "                EtaList,\n",
    "                LambdaList,\n",
    "                PsiList,\n",
    "                DeltaList,\n",
    "                AlphaList,\n",
    "                sigma,\n",
    "                itInd,\n",
    "                modelData,\n",
    "                priorHyperParList,\n",
    "                rLParList,\n",
    "                rLDataParList,\n",
    "            )\n",
    "\n",
    "            samInd = tf.cast(\n",
    "                (i - self.params[\"transient\"] + 1) / self.params[\"thinN\"] - 1, tf.int32\n",
    "            )\n",
    "            if i % self.params[\"thinN\"] == 0:\n",
    "                tf.py_function(\n",
    "                    func=printFunction,\n",
    "                    inp=[i, samInd, [tf.shape(Lambda) for Lambda in LambdaList]],\n",
    "                    Tout=[],\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                i >= self.params[\"transient\"]\n",
    "                and (i - self.params[\"transient\"] + 1) % self.params[\"thinN\"] == 0\n",
    "            ):\n",
    "                samplesEtaList = [\n",
    "                    samplesEta.write(samInd, Eta)\n",
    "                    for samplesEta, Eta in zip(samplesEtaList, EtaList)\n",
    "                ]\n",
    "                \"\"\"\n",
    "                samplesGamma = samplesGamma.write(samInd, Gamma)\n",
    "                samplesiV = samplesiV.write(samInd, iV)\n",
    "                samplesBeta = samplesBeta.write(samInd, Beta)\n",
    "                samplesSigma = samplesSigma.write(samInd, sigma)\n",
    "                samplesLambdaList = [\n",
    "                    samplesLambda.write(samInd, Lambda)\n",
    "                    for samplesLambda, Lambda in zip(samplesLambdaList, LambdaList)\n",
    "                ]\n",
    "                samplesEtaList = [\n",
    "                    samplesEta.write(samInd, Eta)\n",
    "                    for samplesEta, Eta in zip(samplesEtaList, EtaList)\n",
    "                ]\n",
    "                samplesPsiList = [\n",
    "                    samplesPsi.write(samInd, Psi)\n",
    "                    for samplesPsi, Psi in zip(samplesPsiList, PsiList)\n",
    "                ]\n",
    "                samplesDeltaList = [\n",
    "                    samplesDelta.write(samInd, Delta)\n",
    "                    for samplesDelta, Delta in zip(samplesDeltaList, DeltaList)\n",
    "                ]\n",
    "                # print(samInd, samplesGamma.read(samInd))\n",
    "                \"\"\"\n",
    "        \"\"\"\n",
    "        resList = [\n",
    "            samples.stack()\n",
    "            for samples in [samplesBeta, samplesGamma, samplesiV, samplesSigma]\n",
    "        ]\n",
    "        resList += [[samplesLambda.stack() for samplesLambda in samplesLambdaList]]\n",
    "        resList += [[samplesEta.stack() for samplesEta in samplesEtaList]]\n",
    "        resList += [[samplesPsi.stack() for samplesPsi in samplesPsiList]]\n",
    "        resList += [[samplesDelta.stack() for samplesDelta in samplesDeltaList]]\n",
    "        \"\"\"\n",
    "        resList = [[samplesEta.stack() for samplesEta in samplesEtaList]]\n",
    "\n",
    "        return resList\n",
    "\n",
    "\n",
    "sampler = GibbsSampler(nChains=2, samN=10, thinN=10)\n",
    "postList = sampler(\n",
    "    Z,\n",
    "    Beta,\n",
    "    Gamma,\n",
    "    iV,\n",
    "    EtaList,\n",
    "    LambdaList,\n",
    "    PsiList,\n",
    "    DeltaList,\n",
    "    AlphaList,\n",
    "    sigma,\n",
    "    modelData,\n",
    "    priorHyperParList,\n",
    "    rLParList,\n",
    "    rLDataParList,\n",
    ")\n",
    "\n",
    "# print([item for item in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc2968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d156f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa30741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/Users/gtikhono/Downloads/importExport/\"\n",
    "path = '/users/anisjyu/Documents/demo-import/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056c1537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Y', 'XData', 'XFormula', 'X', 'XScaled', 'XRRRData', 'XRRRFormula', 'XRRRScaled', 'YScaled', 'XInterceptInd', 'studyDesign', 'ranLevels', 'ranLevelsUsed', 'dfPi', 'rL', 'Pi', 'TrData', 'TrFormula', 'Tr', 'TrScaled', 'TrInterceptInd', 'C', 'phyloTree', 'distr', 'ny', 'ns', 'nc', 'ncNRRR', 'ncRRR', 'ncORRR', 'ncsel', 'nr', 'nt', 'nf', 'ncr', 'ncs', 'np', 'spNames', 'covNames', 'trNames', 'rLNames', 'XScalePar', 'XRRRScalePar', 'YScalePar', 'TrScalePar', 'V0', 'f0', 'mGamma', 'UGamma', 'aSigma', 'bSigma', 'nu', 'a1', 'b1', 'a2', 'b2', 'rhopw', 'nuRRR', 'a1RRR', 'b1RRR', 'a2RRR', 'b2RRR', 'samples', 'transient', 'thin', 'verbose', 'adaptNf', 'initPar', 'repN', 'randSeed', 'postList', 'call', 'HmscVersion', 'repList'])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Option 3. Using jsonify\n",
    "#\n",
    "\n",
    "import json\n",
    "\n",
    "with open(path + 'obj-complete.json') as json_file:\n",
    "    obj = json.load(json_file)\n",
    "\n",
    "print(obj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edd3debf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nChains = int(np.squeeze(len(obj['postList'])))\n",
    "nChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3c0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = np.float64\n",
    "\n",
    "ny = int(np.squeeze(obj.get('ny'))) # 50\n",
    "ns = int(np.squeeze(obj.get('ns'))) # 4\n",
    "nc = int(np.squeeze(obj.get('nc'))) # 3\n",
    "nt = int(np.squeeze(obj.get('nt'))) # 3\n",
    "nr = int(np.squeeze(obj.get('nr'))) # 2\n",
    "\n",
    "nu = np.squeeze([obj.get('rL')[key]['nu'] for key in obj.get('rL').keys()])\n",
    "a1 = np.squeeze([obj.get('rL')[key]['a1'] for key in obj.get('rL').keys()])\n",
    "b1 = np.squeeze([obj.get('rL')[key]['b1'] for key in obj.get('rL').keys()])\n",
    "a2 = np.squeeze([obj.get('rL')[key]['a2'] for key in obj.get('rL').keys()])\n",
    "b2 = np.squeeze([obj.get('rL')[key]['b2'] for key in obj.get('rL').keys()])\n",
    "\n",
    "nfMin = np.squeeze([obj.get('rL')[key]['nfMin'] for key in obj.get('rL').keys()])\n",
    "nfMax = np.squeeze([obj.get('rL')[key]['nfMax'] for key in obj.get('rL').keys()])\n",
    "\n",
    "sDim = np.squeeze([obj.get('rL')[key]['sDim'] for key in obj.get('rL').keys()])\n",
    "\n",
    "#alphapw = [obj.get('rL')[key]['alphapw'] for key in obj.get('rL').keys()] # todo\n",
    "#alphapw = [None, np.abs(np.random.normal(size=[101, 2]))]\n",
    "alphapw = [np.abs(np.random.normal(size=[101, 2])), np.abs(np.random.normal(size=[101, 2]))]\n",
    "\n",
    "distr = np.asarray(obj.get('distr')).astype(int)\n",
    "\n",
    "X = np.asarray(obj.get('X'))\n",
    "T = np.asarray(obj.get('Tr'))\n",
    "Y = np.asarray(obj.get('Y'))\n",
    "\n",
    "Pi = np.asarray(obj.get('Pi')).astype(int) - 1\n",
    "npVec = Pi.max(axis=0) + 1\n",
    "\n",
    "nfVec = 3 + np.arange(nr)\n",
    "\n",
    "mGamma = np.asarray(obj.get('mGamma'))\n",
    "iUGamma = np.asarray(obj.get('UGamma'))\n",
    "\n",
    "aSigma = np.asarray(obj.get('aSigma'))\n",
    "bSigma = np.asarray(obj.get('bSigma'))\n",
    "\n",
    "V0 = np.squeeze(obj.get('V0'))\n",
    "f0 = int(np.squeeze(obj.get('f0')))\n",
    "\n",
    "WgList = [tfr.normal([101,npVec[r],npVec[r]], dtype=dtype) for r in range(nr)]\n",
    "WgList = [tf.matmul(WgList[r], WgList[r], transpose_a=True) for r in range(nr)] # these MUST be SPD matrices!\n",
    "iWgList = [tfla.inv(WgList[r]) for r in range(nr)]\n",
    "LiWgList = [tfla.cholesky(iWgList[r]) for r in range(nr)]\n",
    "detWgList = [tfr.normal([101], dtype=dtype) for r in range(nr)]\n",
    "\n",
    "#modelDataList = [Y, X, T, Pi, distr]\n",
    "#priorHyperParams = [mGamma, iUGamma, f0, V0, aSigma, bSigma]\n",
    "#rLParList = [[nu[r], a1[r], b1[r], a2[r], b2[r], nfMin[r], nfMax[r], sDim[r], alphapw[r], npVec[r]] for r in range(nr)]\n",
    "#rLDataParList = [[WgList[r], iWgList[r], LiWgList[r], detWgList[r]] for r in range(nr)]\n",
    "#rLParList = [nu, a1, b1, a2, b2, nfMin, nfMax, sDim, alphapw]\n",
    "#rLDataParList = [WgList, iWgList, LiWgList, detWgList]\n",
    "\n",
    "modelData = {}\n",
    "modelData['Y'] = Y\n",
    "modelData['X'] = X\n",
    "modelData['T'] = T\n",
    "modelData['Pi'] = Pi\n",
    "modelData['distr'] = distr\n",
    "\n",
    "priorHyperParams = {}\n",
    "priorHyperParams['mGamma'] = mGamma\n",
    "priorHyperParams['iUGamma'] = iUGamma\n",
    "priorHyperParams['f0'] = f0\n",
    "priorHyperParams['V0'] = V0\n",
    "priorHyperParams['aSigma'] = aSigma\n",
    "priorHyperParams['bSigma'] = bSigma\n",
    "\n",
    "rLDataParams = {}\n",
    "rLDataParams['Wg'] = WgList\n",
    "rLDataParams['iWg'] = iWgList\n",
    "rLDataParams['LiWg'] = LiWgList\n",
    "rLDataParams['detWg'] = detWgList\n",
    "\n",
    "rLParams = {}\n",
    "\n",
    "rLParams['nu'] = nu \n",
    "rLParams['a1'] = a1 \n",
    "rLParams['b1'] = b1 \n",
    "rLParams['a2'] = a2 \n",
    "rLParams['b2'] = b2\n",
    "rLParams['nfMin'] = nfMin \n",
    "rLParams['nfMax'] = nfMax \n",
    "rLParams['sDim'] = sDim\n",
    "rLParams['alphapw'] = alphapw\n",
    "\n",
    "np.random.seed(1)\n",
    "tfr.set_seed(1)\n",
    "\n",
    "aDeltaList = [tf.concat([a1[r]*tf.ones([1,1], dtype), a2[r]*tf.ones([nfVec[r]-1,1], dtype)], 0) for r in range(nr)]\n",
    "bDeltaList = [tf.concat([b1[r]*tf.ones([1,1], dtype), b2[r]*tf.ones([nfVec[r]-1,1], dtype)], 0) for r in range(nr)]\n",
    "\n",
    "Beta = tfr.normal([nc,ns], dtype=dtype)\n",
    "Gamma = tfr.normal([nc,nt], dtype=dtype)\n",
    "iV = tf.ones([nc,nc], dtype=dtype) + tf.eye(nc, dtype=dtype)\n",
    "EtaList = [tfr.normal([npVec[r],nfVec[r]], dtype=dtype) for r in range(nr)]\n",
    "PsiList = [1 + tf.abs(tfr.normal([nfVec[r],ns], dtype=dtype)) for r in range(nr)]\n",
    "DeltaList = [np.random.gamma(aDeltaList[r], bDeltaList[r], size=[nfVec[r],1]) for r in range(nr)]\n",
    "LambdaList = [tfr.normal([nfVec[r],ns], dtype=dtype) for r in range(nr)]\n",
    "AlphaList = [tf.zeros([nfVec[r],1], dtype=tf.int64) for r in range(nr)]\n",
    "Z = tf.zeros_like(Y)\n",
    "\n",
    "sigma = tf.abs(tfr.normal([ns], dtype=dtype))*(distr[:,1]==1) + tf.ones([ns], dtype=dtype)*(distr[:,1]==0)\n",
    "#sigma = tf.ones(ns, dtype=dtype)\n",
    "iSigma = 1/sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c213072",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = modelData\n",
    "prior_params = priorHyperParams\n",
    "random_level_data_params = rLDataParams\n",
    "random_level_params = rLParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e52561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723fb078",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateEta:\n",
    "    def __init__(self, params, dtype=np.float64):\n",
    "        self.params = params\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def sampler(params):\n",
    "\n",
    "        sigma = self.params[\"sigma\"]\n",
    "        sDim = self.params[\"sDim\"]\n",
    "        Pi = self.params[\"Pi\"]\n",
    "\n",
    "        Z = self.params[\"Z\"]\n",
    "        Beta = self.params[\"Beta\"]\n",
    "        EtaList = self.params[\"Eta\"]\n",
    "        LambdaList = self.params[\"Lambda\"]\n",
    "        AlphaList = self.params[\"Alpha\"]\n",
    "        X = self.params[\"X\"]\n",
    "        iWgList = self.params[\"iWg\"]\n",
    "\n",
    "        npVec = tf.reduce_max(Pi, 0) + 1\n",
    "\n",
    "        nr = len(LambdaList)\n",
    "\n",
    "        LFix = tf.matmul(X, Beta)\n",
    "\n",
    "        LRanLevelList = [None] * nr\n",
    "        for r, (Eta, Lambda) in enumerate(zip(EtaList, LambdaList)):\n",
    "            LRanLevelList[r] = tf.matmul(tf.gather(Eta, Pi[:, r]), Lambda)\n",
    "\n",
    "        iD = tf.ones_like(Z) * sigma**-2\n",
    "\n",
    "        EtaListNew = [None] * nr\n",
    "\n",
    "        for r, (Eta, Lambda, Alpha, iWg) in enumerate(\n",
    "            zip(EtaList, LambdaList, AlphaList, iWgList)\n",
    "        ):\n",
    "\n",
    "            S = (\n",
    "                Z\n",
    "                - LFix\n",
    "                - sum([LRanLevelList[rInd] for rInd in np.setdiff1d(np.arange(nr), r)])\n",
    "            )\n",
    "\n",
    "            nf = tf.cast(tf.shape(Lambda)[-2], tf.int64)\n",
    "\n",
    "            LamInvSigLam = tf.scatter_nd(\n",
    "                Pi[:, r, None],\n",
    "                tf.einsum(\"hj,ij,kj->ihk\", Lambda, iD, Lambda),\n",
    "                tf.stack([npVec[r], nf, nf]),\n",
    "            )\n",
    "\n",
    "            mu0 = tf.scatter_nd(\n",
    "                Pi[:, r, None],\n",
    "                tf.matmul(iD * S, Lambda, transpose_b=True),\n",
    "                tf.stack([npVec[r], nf]),\n",
    "            )\n",
    "\n",
    "            if sDim[r] > 0:\n",
    "                Eta = modelSpatialFull(\n",
    "                    Eta, Lambda, LamInvSigLam, mu0, Alpha, iWg, npVec[r], nf\n",
    "                )\n",
    "            else:\n",
    "                Eta = modelNonSpatial(Eta, Lambda, LamInvSigLam, mu0, npVec[r], nf)\n",
    "\n",
    "            EtaListNew[r] = Eta\n",
    "\n",
    "            LRanLevelList[r] = tf.matmul(tf.gather(EtaListNew[r], Pi[:, r]), Lambda)\n",
    "\n",
    "        return EtaListNew\n",
    "\n",
    "    def modelSpatialFull(\n",
    "        Eta, Lambda, LamInvSigLam, mu0, Alpha, iWg, np, nf, dtype=np.float64\n",
    "    ):\n",
    "        iWs = tf.reshape(\n",
    "            tf.transpose(\n",
    "                tfla.diag(\n",
    "                    tf.transpose(tf.gather(iWg, tf.squeeze(Alpha, -1)), [1, 2, 0])\n",
    "                ),\n",
    "                [2, 0, 3, 1],\n",
    "            ),\n",
    "            [nf * np, nf * np],\n",
    "        )\n",
    "        iUEta = iWs + tf.reshape(\n",
    "            tf.transpose(\n",
    "                tfla.diag(tf.transpose(LamInvSigLam, [1, 2, 0])), [0, 2, 1, 3]\n",
    "            ),\n",
    "            [nf * np, nf * np],\n",
    "        )\n",
    "        LiUEta = tfla.cholesky(iUEta)\n",
    "        mu1 = tfla.triangular_solve(LiUEta, tf.reshape(tf.transpose(mu0), [nf * np, 1]))\n",
    "        eta = tfla.triangular_solve(\n",
    "            LiUEta, mu1 + tfr.normal([nf * np, 1], dtype=dtype), adjoint=True\n",
    "        )\n",
    "        Eta = tf.transpose(tf.reshape(eta, [nf, np]))\n",
    "        return Eta\n",
    "\n",
    "    def modelNonSpatial(Eta, Lambda, LamInvSigLam, mu0, np, nf, dtype=np.float64):\n",
    "        iV = tf.eye(nf, dtype=dtype) + LamInvSigLam\n",
    "        LiV = tfla.cholesky(iV + tf.eye(nf, dtype=dtype))\n",
    "        mu1 = tfla.triangular_solve(LiV, tf.expand_dims(mu0, -1))\n",
    "        Eta = tf.squeeze(\n",
    "            tfla.triangular_solve(\n",
    "                LiV, mu1 + tfr.normal([np, nf, 1], dtype=dtype), adjoint=True\n",
    "            ),\n",
    "            -1,\n",
    "        )\n",
    "        return Eta\n",
    "\n",
    "    def modelSpatialNNGP(self, Eta, Lambda):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def modelSpatialGPP(self, Eta, Lambda):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __getitem__(self, position):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "# obj = UpdateEta(sigma, sDim, Pi)\n",
    "# res = obj(Z, Beta, EtaList, LambdaList, AlphaList, modelData, rLDataParList)\n",
    "\n",
    "# print([res[r].shape for r in range(len(res))])\n",
    "\n",
    "# print([item for item in res])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
